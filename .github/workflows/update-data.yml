name: Update Measles Data Visualization

on:
  schedule:
    - cron: '0 6 * * *'
  
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      force_refresh:
        description: 'Force refresh all data (ignore cache)'
        required: false
        default: 'false'
        type: boolean

  # Run on push to main branch for testing
  push:
    branches: [ main ]

jobs:
  update-visualizations:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write  # Allow pushing changes back to repo
      pages: write     # Allow deploying to GitHub Pages
      id-token: write  # Allow OIDC token for Pages deployment

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for proper git operations

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directories
      run: |
        mkdir -p data/backups
        mkdir -p data/weekly_tracking
        mkdir -p docs

    - name: Debug - Check weekly history BEFORE running
      run: |
        echo "=== Current working directory ==="
        pwd
        
        echo ""
        echo "=== Repository structure ==="
        ls -la
        
        echo ""
        echo "=== Data directory ==="
        ls -la data/ || echo "data/ directory doesn't exist"
        
        echo ""
        echo "=== Weekly tracking directory ==="
        ls -la data/weekly_tracking/ || echo "data/weekly_tracking/ directory doesn't exist"
        
        echo ""
        echo "=== Checking for weekly history file ==="
        if [ -f "data/weekly_tracking/weekly_history.json" ]; then
          echo "✓ File EXISTS"
          echo "Size: $(wc -c < data/weekly_tracking/weekly_history.json) bytes"
          echo "Lines: $(wc -l < data/weekly_tracking/weekly_history.json)"
          echo ""
          echo "First 500 characters:"
          head -c 500 data/weekly_tracking/weekly_history.json
          echo ""
          echo ""
          echo "Validating JSON:"
          python3 -c "
import json
import sys
try:
    with open('data/weekly_tracking/weekly_history.json', 'r') as f:
        data = json.load(f)
    print(f'✓ Valid JSON with {len(data)} week entries')
    for i, week in enumerate(data):
        week_id = week.get('week', 'unknown')
        date = week.get('date', 'unknown')
        num_states = len(week.get('data', []))
        print(f'  Week {i+1}: {week_id} ({date}) - {num_states} states')
except Exception as e:
    print(f'✗ JSON validation failed: {e}')
    sys.exit(1)
          "
        else
          echo "✗ File DOES NOT EXIST"
        fi

    - name: Backup existing visualizations
      run: |
        # Create a backup of current visualizations before attempting update
        if [ -d "docs" ] && [ "$(ls -A docs)" ]; then
          mkdir -p data/viz_backups
          timestamp=$(date +%Y%m%d_%H%M%S)
          cp -r docs "data/viz_backups/docs_${timestamp}"
          echo "Backed up existing visualizations to data/viz_backups/docs_${timestamp}"
          
          # Keep only last 5 visualization backups
          cd data/viz_backups
          ls -t | tail -n +6 | xargs -r rm -rf
          cd ../..
        else
          echo "No existing visualizations to backup"
        fi

    - name: Run data update and visualization generation
      id: update
      continue-on-error: true  # Don't fail workflow if update fails
      run: |
        python main.py
      env:
        FORCE_REFRESH: ${{ github.event.inputs.force_refresh || 'false' }}

    - name: Debug - Check weekly history AFTER running
      if: always()
      run: |
        echo "=== After Python execution ==="
        if [ -f "data/weekly_tracking/weekly_history.json" ]; then
          echo "✓ File EXISTS"
          echo "Size: $(wc -c < data/weekly_tracking/weekly_history.json) bytes"
          echo "Lines: $(wc -l < data/weekly_tracking/weekly_history.json)"
          echo ""
          echo "Last 1000 characters:"
          tail -c 1000 data/weekly_tracking/weekly_history.json
          echo ""
          echo ""
          echo "Validating JSON:"
          python3 -c "
import json
try:
    with open('data/weekly_tracking/weekly_history.json', 'r') as f:
        data = json.load(f)
    print(f'✓ Valid JSON with {len(data)} week entries')
    for i, week in enumerate(data):
        week_id = week.get('week', 'unknown')
        date = week.get('date', 'unknown')
        num_states = len(week.get('data', []))
        total_cases = sum(s.get('Cases', 0) for s in week.get('data', []))
        print(f'  Week {i+1}: {week_id} ({date}) - {num_states} states, {total_cases} total cases')
except Exception as e:
    print(f'✗ JSON validation failed: {e}')
          "
        else
          echo "✗ File DOES NOT EXIST"
        fi
        
        echo ""
        echo "=== Docs directory ==="
        ls -lh docs/ || echo "Docs directory empty/missing"

    - name: Check update status
      id: check_status
      run: |
        if [ ${{ steps.update.outcome }} == 'success' ]; then
          echo "update_successful=true" >> $GITHUB_OUTPUT
          echo "Update completed successfully"
        else
          echo "update_successful=false" >> $GITHUB_OUTPUT
          echo "Update failed, checking for existing visualizations..."
          
          # Check if we have visualizations to use
          if [ -d "docs" ] && [ "$(ls -A docs/*.html 2>/dev/null)" ]; then
            echo "Existing visualizations found, will use those"
            echo "has_fallback=true" >> $GITHUB_OUTPUT
          else
            echo "No existing visualizations found"
            echo "has_fallback=false" >> $GITHUB_OUTPUT
          fi
        fi

    - name: Restore from backup if update failed
      if: steps.check_status.outputs.update_successful == 'false' && steps.check_status.outputs.has_fallback == 'false'
      run: |
        # Try to restore from most recent visualization backup
        if [ -d "data/viz_backups" ] && [ "$(ls -A data/viz_backups)" ]; then
          latest_backup=$(ls -t data/viz_backups | head -n1)
          echo "Restoring from backup: ${latest_backup}"
          cp -r "data/viz_backups/${latest_backup}"/* docs/
          echo "Restored visualizations from backup"
        else
          echo "No backup available to restore"
          exit 1
        fi

    - name: Check for changes
      id: verify-changed-files
      run: |
        # Explicitly add files we want to track
        git add docs/ || true
        git add data/backups/ || true
        git add data/weekly_tracking/ || true
        
        if [ -n "$(git status --porcelain)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
          echo "Changes detected:"
          git status --short
        else
          echo "changed=false" >> $GITHUB_OUTPUT
          echo "No changes detected"
        fi

    - name: Commit and push changes
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Show what we're committing
        echo "Files to commit:"
        git status --short
        
        # Add status message to commit
        if [ "${{ steps.check_status.outputs.update_successful }}" == "true" ]; then
          git commit -m "Auto-update measles visualizations - $(date -u +%Y-%m-%d\ %H:%M\ UTC)"
        else
          git commit -m "Maintain visualizations (update failed, using existing) - $(date -u +%Y-%m-%d\ %H:%M\ UTC)"
        fi
        
        git push

    - name: Setup Pages
      if: always()  # Always deploy, even if update failed but we have visualizations
      uses: actions/configure-pages@v4
      
    - name: Upload to GitHub Pages
      if: always()  # Always upload available visualizations
      uses: actions/upload-pages-artifact@v4
      with:
        path: ./docs

    - name: Deploy to GitHub Pages
      if: always()  # Always deploy available content
      id: deployment
      uses: actions/deploy-pages@v4

    - name: Log completion
      if: always()
      run: |
        echo "Workflow completed at $(date -u +%Y-%m-%d\ %H:%M\ UTC)"
        echo "Update successful: ${{ steps.check_status.outputs.update_successful }}"
        echo "Site URL: ${{ steps.deployment.outputs.page_url }}"
        
        if [ "${{ steps.check_status.outputs.update_successful }}" == "false" ]; then
          echo "⚠️  Warning: Update failed but visualizations are still available"
        fi

  # Job to clean up old backups (keep last 30 days of data backups, last 7 days of viz backups)
  cleanup-backups:
    runs-on: ubuntu-latest
    needs: update-visualizations
    if: success()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Clean up old backups
      run: |
        # Remove DATA backup files older than 30 days (but keep at least 5 most recent)
        if [ -d "data/backups" ]; then
          backup_count=$(find data/backups -type f | wc -l)
          echo "Current data backup count: $backup_count"
          
          # Only delete old files if we have more than 5 backups
          if [ $backup_count -gt 5 ]; then
            find data/backups -name "*.csv" -mtime +30 -delete
            find data/backups -name "*.json" -mtime +30 -delete
          fi
          
          remaining_count=$(find data/backups -type f | wc -l)
          echo "Remaining data backup files: $remaining_count"
        fi
        
        # Remove VISUALIZATION backup folders older than 7 days (but keep at least 3 most recent)
        if [ -d "data/viz_backups" ]; then
          viz_backup_count=$(find data/viz_backups -maxdepth 1 -type d | wc -l)
          echo "Current viz backup count: $viz_backup_count"
          
          # Only delete old folders if we have more than 3 backups
          if [ $viz_backup_count -gt 3 ]; then
            find data/viz_backups -maxdepth 1 -type d -mtime +7 -exec rm -rf {} +
          fi
          
          remaining_viz_count=$(find data/viz_backups -maxdepth 1 -type d | wc -l)
          echo "Remaining viz backup folders: $remaining_viz_count"
        fi

    - name: Commit backup cleanup
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/backups data/viz_backups
          git commit -m "Cleanup old backup files - $(date -u +%Y-%m-%d)"
          git push
        fi

  # Health check job to verify site is working
  health-check:
    runs-on: ubuntu-latest
    needs: update-visualizations
    if: always()  # Run even if update failed
    
    steps:
    - name: Wait for deployment
      run: sleep 60  # Give Pages time to deploy
      
    - name: Check site health
      run: |
        # Get the repository info to construct the Pages URL
        REPO_NAME="${GITHUB_REPOSITORY#*/}"
        OWNER="${GITHUB_REPOSITORY%/*}"
        SITE_URL="https://${OWNER}.github.io/${REPO_NAME}"
        
        echo "Checking site health at: $SITE_URL"
        
        # Check if the main page loads
        if curl -f -s -I "$SITE_URL" > /dev/null; then
          echo "✓ Site is accessible"
        else
          echo "✗ Site health check failed"
          exit 1
        fi
        
        # Check if key pages load
        all_passed=true
        for page in timeline.html recent_trends.html state_map.html southwest_weekly.html; do
          if curl -f -s -I "$SITE_URL/$page" > /dev/null; then
            echo "✓ $page is accessible"
          else
            echo "✗ $page health check failed"
            all_passed=false
          fi
        done
        
        if [ "$all_passed" = false ]; then
          echo "Some health checks failed"
          exit 1
        fi
        
        echo "All health checks passed"
        echo "Site URL: $SITE_URL"

  # Send notification on failure
  notify-on-failure:
    runs-on: ubuntu-latest
    needs: [update-visualizations, health-check]
    if: failure()
    
    steps:
    - name: Notify on workflow failure
      run: |
        echo "Workflow failed. Consider setting up notifications here."
        echo "Failed at: $(date -u +%Y-%m-%d\ %H:%M\ UTC)"
        echo "Repository: $GITHUB_REPOSITORY"
        echo "Run ID: $GITHUB_RUN_ID"
        
        # Example: You can add Slack webhook, email, or other notifications here
        # curl -X POST -H 'Content-type: application/json' \
        #   --data '{"text":"Measles viz update failed!"}' \
        #   $SLACK_WEBHOOK_URL
